{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acae055e",
   "metadata": {},
   "source": [
    "# 自行開發模組(module)\n",
    "\n",
    "\n",
    "一個模組(module)就是一個python檔案。建立module的目的:\n",
    "- 將關聯性較高的程式碼統一放在一個地方，便於維護。需要使用的時候，可以用`from ... import...`來達成。\n",
    "- 或是直接`import <module name>`來使用。\n",
    "\n",
    "\n",
    "module中，可以包含`function`以及`class`。在import後面接上要使用的function或是class名稱即可。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ca974b",
   "metadata": {},
   "source": [
    "<font color=\"chocolate\">另一個概念為`套件(package)`，就是一個資料夾，裡面可以放很多個module，且擁有`__init__.py`檔案，其中可以撰寫package初始化的程式碼。</br>\n",
    "package的出現是為了當相似的module很多時，作為組織module用。\n",
    "使用package的方法也是`from ... import...`或`import ...`。</br>\n",
    "`...`可以是module名稱，或是`<module name>.<function or class>`。\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67774de",
   "metadata": {},
   "source": [
    "使用jupyter notebook開發出來的python檔，並非單純的python檔，而是json格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5cffc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def for_test(*args):\n",
    "    print('成功引用Apriori module囉!')\n",
    "    print('args: ', args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b28043",
   "metadata": {},
   "source": [
    "## 需要將.ipynb轉成.py才能夠被其他python檔給import做使用!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "76440c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook Apriori.ipynb to script\n",
      "[NbConvertApp] Writing 11623 bytes to Apriori.py\n"
     ]
    }
   ],
   "source": [
    "#將.ipynb檔轉成.py檔 -> 以利其他python檔的import\n",
    "!jupyter nbconvert --to script Apriori.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20fe013b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#global variable定義\n",
    "support = 0.6\n",
    "confidence = 0.6\n",
    "size = 2\n",
    "itemset_dict = {}  #用來存放frequent itemset的dict。每個itemset用tuple來存放; 存size = 1 開始\n",
    "#temp_dict = {}  #用來存放itemset()回傳的list，若為空list，則得到的frequent itemset list 為 itemset_list\n",
    "frequent_itemset_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7a350e",
   "metadata": {},
   "source": [
    "# 建立Apriori Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fd1c536",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "#support的計算 -> bug!\n",
    "def supp(item, df):\n",
    "    result = {}\n",
    "    item = tuple(item)\n",
    "    total_row = len(df.index)\n",
    "    for i in range(total_row):\n",
    "        temp_row = df.iloc[i]\n",
    "        #print(temp_row)\n",
    "        \n",
    "        if(all(k in temp_row.values for k in item) and (tuple(item) not in list(result.keys()))):\n",
    "            result[tuple(item)] = 1\n",
    "            #print('有建立')\n",
    "        elif(all(k in temp_row.values for k in item) and (tuple(item) in list(result.keys()))):\n",
    "            result[tuple(item)] = result[tuple(item)] + 1\n",
    "            #print('加1')\n",
    "        else:\n",
    "            #print('不符合')\n",
    "            #print([k for k in key])\n",
    "            continue\n",
    "    \n",
    "    #print('內部統計結果dict: ',inner_temp_dict)\n",
    "    #print('supp中的result: ', result)\n",
    "    return result[tuple(item)] / total_row if item in list(result.keys()) else 0\n",
    "\n",
    "#confidence計算\n",
    "def conf(x, item, df):\n",
    "    #print('x: ', x)\n",
    "    #print('item: ', item)\n",
    "    return supp(list(item), df) / supp(list(x), df) \n",
    "\n",
    "\n",
    "\n",
    "#lift計算\n",
    "def lift(x, y, item, df):\n",
    "    #print('lift的item: ', item)\n",
    "    #print('supp(item, df): ', supp(list(item), df))\n",
    "    #print('supp(x, df): ', supp(list(x), df))\n",
    "    #print('supp(y, df): ', supp(list(y), df))\n",
    "    return supp(list(item), df) / (supp(list(x), df) * supp(list(y), df))\n",
    "\n",
    "\n",
    "\n",
    "#增加itemset size並且做篩選\n",
    "def itemset(inner_size, items, df):\n",
    "    #print('成功呼叫itemset() function')\n",
    "    #print('傳入的itemset: ',items)\n",
    "    \n",
    "    \"\"\"\n",
    "    #將小於support值的itemset給濾掉\n",
    "    print('itemset內的support: ', support)\n",
    "    filtered_item_dict = filter(lambda x:(x[1] / len(df.index) >= support), items.items())\n",
    "    filtered_item_dict = dict(filtered_item_dict)\n",
    "    #print('過濾後: ',filtered_item_dict)\n",
    "    \"\"\"\n",
    "    \n",
    "    #建立size+1 的itemset_dict\n",
    "    keys = list(items.keys())\n",
    "    #print('keys: ', keys)\n",
    "    \n",
    "    temp_keys_list = []\n",
    "    for i in range(len(keys)):\n",
    "        for j in range(i+1, len(keys)):\n",
    "            combined_key_list = list(keys[i]) + list(keys[j])\n",
    "            #print('組合的key: ',combined_key_list)\n",
    "            \n",
    "            combination_key_list = tuple(set(combined_key_list))\n",
    "            temp_keys_list.append(combination_key_list)\n",
    "    #print('排列組合後的keys: ', temp_keys_list)\n",
    "    \n",
    "    #排除size != size的組合，且把重複的組合留下唯一一組\n",
    "    filtered_keys_list = list(set([key for key in temp_keys_list if len(key) == inner_size]))\n",
    "    #print('itemset符合size的keys: ',filtered_keys_list)\n",
    "    \n",
    "    #與原dataframe比較，針對每個key(tuple構成的)去做統計(計數)\n",
    "    inner_temp_dict = {}\n",
    "    total_row = len(df.index)\n",
    "    for i in range(total_row):\n",
    "        temp_row = df.iloc[i]\n",
    "        #print(temp_row)\n",
    "        for key in filtered_keys_list:\n",
    "            if(all(k in temp_row.values for k in key) and (key not in list(inner_temp_dict.keys()))):\n",
    "                inner_temp_dict[key] = 1\n",
    "                #print('有建立')\n",
    "            elif(all(k in temp_row.values for k in key) and (key in list(inner_temp_dict.keys()))):\n",
    "                inner_temp_dict[key] = inner_temp_dict[key] + 1\n",
    "                #print('加1')\n",
    "            else:\n",
    "                #print('不符合')\n",
    "                #print([k for k in key])\n",
    "                continue\n",
    "    \n",
    "    #print('itemset內部統計結果dict: ',inner_temp_dict)\n",
    "    \n",
    "    #過濾掉<support的部分\n",
    "    filtered_item_dict = filter(lambda x:(x[1] / len(df.index) >= support), inner_temp_dict.items())\n",
    "    inner_temp_dict = dict(filtered_item_dict)\n",
    "    #print('itemset內部過濾後的dict: ', inner_temp_dict)\n",
    "    \n",
    "    #回傳True or False決定是否要繼續計算\n",
    "    if(inner_temp_dict != {}):\n",
    "        global itemset_dict\n",
    "        itemset_dict = inner_temp_dict.copy()\n",
    "        \n",
    "        global size\n",
    "        size = inner_size + 1\n",
    "        return True\n",
    "    else:\n",
    "        print('Frequent itemset建立完成 ...')\n",
    "        return False\n",
    "\n",
    "    \n",
    "#定義組合的function -> 用於產生所有的S組合\n",
    "#lt: 輸入進來的list; n: 組合的元素有n個\n",
    "def combine(lt, n):\n",
    "    #print('呼叫combine')\n",
    "    answers = []\n",
    "    tmp_item = [0] * n\n",
    "    def next_it(lt_lbound, ni):\n",
    "        if(ni == n):\n",
    "            answers.append(tmp_item.copy())\n",
    "            return\n",
    "        for li in range(lt_lbound, len(lt)):\n",
    "            tmp_item[ni] = lt[li]\n",
    "            next_it(li + 1, ni + 1)\n",
    "    next_it(0, 0)\n",
    "    return answers\n",
    "\n",
    "\n",
    "    \n",
    "#從itemset(I)中計算 S -> I-S 的機率是否 >= confidence。留下符合的並return\n",
    "def compare_with_confidence(freq_list, df):\n",
    "    print('過濾掉小於confidence值的組合 ...')\n",
    "    \n",
    "    #result_df = pd.DataFrame()\n",
    "    \n",
    "    #test = combine(freq_list, 2)\n",
    "        \n",
    "    \n",
    "    #找出每個frequent itemset的S\n",
    "    combination = {}        \n",
    "    #print('combination: ', combination)\n",
    "    for item in freq_list:\n",
    "        combination[item] = list()\n",
    "        for n in range(1, len(item)):\n",
    "            #print('item: ', combination[item])\n",
    "            combination[item].extend(combine(item, n).copy())\n",
    "    #print('組合結果: ', combination)   \n",
    "    \n",
    "    \n",
    "    #根據S找出I-S，然後計算confidence\n",
    "    pass_confidence = {}\n",
    "    for k, v in combination.items():\n",
    "        pass_confidence[k] = {}\n",
    "        for s in v:\n",
    "            I_S = tuple(filter(lambda x:x not in s, k))\n",
    "            #print(I_S)\n",
    "            #initialize\n",
    "            pass_confidence[k][tuple(s)] = [I_S, conf(s, k, df)]\n",
    "    \n",
    "    #print('計算confidence之後: ', pass_confidence)\n",
    "    \n",
    "    #濾掉 < confidence 最小值的資料\n",
    "    prepare_to_remove = []\n",
    "    for k, v in pass_confidence.items():\n",
    "        for s, vi in v.items():\n",
    "            if(vi[1] < confidence):\n",
    "                prepare_to_remove.append([k, s])\n",
    "                #pass_confidence[k].pop(s)\n",
    "                \n",
    "                \n",
    "    #pass_confidence[ks[0]].pop(ks[1]) for ks in prepare_to_remove\n",
    "    for ks in prepare_to_remove:\n",
    "        pass_confidence[ks[0]].pop(ks[1])\n",
    "        \n",
    "        \n",
    "    #print('過濾掉confidence太小之後: ', pass_confidence)\n",
    "    #返回dataframe形式的result\n",
    "    # frequent itemset / support / antecedent / consequent / confidence\n",
    "    columns = ['frequent itemset', 'support', 'antecedent', 'consequent', 'confidence', 'lift']\n",
    "    data = []\n",
    "    for k, v in pass_confidence.items():\n",
    "        for s, vi in v.items():\n",
    "            #I_S = tuple(filter(lambda x:x not in s, k))\n",
    "            tmp_row = [k, supp(k, df), s, vi[0], vi[1], lift(s, vi[0], k, df)]\n",
    "            data.append(tmp_row)\n",
    "    \n",
    "    result_df = pd.DataFrame(data = data, columns = columns)\n",
    "    print('apriori algorithm執行完成!')\n",
    "    return result_df\n",
    "    #pass    \n",
    "\n",
    "\n",
    "\n",
    "#進行apriori algorithm\n",
    "def apriori(df):\n",
    "    #df: pandas的dataframe\n",
    "    #為了避免重複執行apriori function時出現\n",
    "    #'ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()'的錯誤，\n",
    "    #需要把global variables\n",
    "    clear_param()\n",
    "      \n",
    "    \n",
    "    #先判斷輸入的資料是否為pandas的dataframe，是的話才繼續下去\n",
    "    if(str(type(df)) == \"<class 'pandas.core.frame.DataFrame'>\"):\n",
    "        #print('符合資料格式，可以繼續做計算。')\n",
    "        #print(df.columns)\n",
    "        \n",
    "        #從dataframe中取得初始條件\n",
    "        #1.資料總筆數\n",
    "        total_row = len(df.index) \n",
    "        \n",
    "        #2.Create size=1的itemset\n",
    "        for i in range(total_row):\n",
    "            temp_row = df.iloc[i]\n",
    "            #print(type(temp_row))\n",
    "            \n",
    "            for j in range(len(temp_row.index)):\n",
    "                #print(type(temp_row[j]))\n",
    "                #temp_idx = map(tuple, temp_row[j])  'numpy.int64' object is not iterable\n",
    "                \n",
    "                global itemset_dict\n",
    "                if(temp_row[j] not in list(itemset_dict.keys())):\n",
    "                    #idx = temp_row[j]\n",
    "                    #temp_tuple = tuple([10])\n",
    "                    #print(type(idx))\n",
    "                    itemset_dict[tuple([temp_row[j]])] = 1\n",
    "                else:\n",
    "                    itemset_dict[tuple([temp_row[j]])] = itemset_dict[tuple([temp_row[j]])] + 1\n",
    "            \n",
    "        #print('輸入的data初始狀態: ', itemset_dict)    \n",
    "        print('開始執行apriori algorithm ...')\n",
    "        \n",
    "        #初步過濾掉<support的值\n",
    "        filtered_item_dict = filter(lambda x:(x[1] / len(df.index) >= support), itemset_dict.items())\n",
    "        itemset_dict = dict(filtered_item_dict)\n",
    "        #print('初始且符合support的itemset: ',itemset_dict)\n",
    "        \n",
    "        \n",
    "        #執行apriori algorithm\n",
    "        while True:\n",
    "            if(itemset(size, itemset_dict, df)):\n",
    "                pass\n",
    "                #print('size+1')\n",
    "                #print(itemset_dict, size)\n",
    "            else:\n",
    "                break\n",
    "            \"\"\"\n",
    "            temp_dict = itemset(size, itemset_dict, df).copy()\n",
    "            if(temp_dict != {}):\n",
    "                size = size + 1\n",
    "                itemset_dict = temp_dict.copy()\n",
    "                \n",
    "            else:\n",
    "                #itemset_dict = temp_dict.copy()\n",
    "                #size = size + 1\n",
    "                break\n",
    "            \"\"\"\n",
    "        #print('最後的itemset結果: ', itemset_dict)\n",
    "        global frequent_itemset_list\n",
    "        #print(itemset_dict.items())\n",
    "        frequent_itemset_list = [k for k, v in itemset_dict.items() if (v / len(df.index)) >= support]\n",
    "        #frequent_itemset_list = ['hahaha']\n",
    "        #print('final的frequent itemsets: ', frequent_itemset_list)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #得到frequent itemsets之後，再來考慮 (S -> I-S) 是否有 >= confidence值\n",
    "        result = compare_with_confidence(frequent_itemset_list, df)\n",
    "        \n",
    "        return result\n",
    "    else:\n",
    "        print('非pandas的dataframe，退回')\n",
    "        print('資料格式為: ', type(df))\n",
    "        return None\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c488ebb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "參數設定完成。support = 0.3, confidence = 0.6\n",
      "support:  0.3\n",
      "confidence:  0.6\n",
      "size:  2\n",
      "itemset_dict:  {}\n",
      "frequent_itemset_list:  []\n",
      "開始執行apriori algorithm ...\n",
      "Frequent itemset建立完成 ...\n",
      "過濾掉小於confidence值的組合 ...\n",
      "apriori algorithm執行完成!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequent itemset</th>\n",
       "      <th>support</th>\n",
       "      <th>antecedent</th>\n",
       "      <th>consequent</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(33.0, 5.0)</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>(33.0,)</td>\n",
       "      <td>(5.0,)</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.530612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(33.0, 5.0)</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>(5.0,)</td>\n",
       "      <td>(33.0,)</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.530612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  frequent itemset   support antecedent consequent  confidence      lift\n",
       "0      (33.0, 5.0)  0.333333    (33.0,)     (5.0,)    0.714286  1.530612\n",
       "1      (33.0, 5.0)  0.333333     (5.0,)    (33.0,)    0.714286  1.530612"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for test\n",
    "\n",
    "df = pd.read_excel('lottery.xlsx', sheet_name= 'big_lottery')\n",
    "\n",
    "#print(df.iloc[[0,1]])  #取得特定row的資料\n",
    "\n",
    "#print(df)\n",
    "#去掉不要的columns\n",
    "exclude_list = ['period','date']  #columns to exclude\n",
    "want_column = [column for column in df.columns.tolist() if column not in exclude_list]\n",
    "#print(want_column)\n",
    "df_pure = df[want_column]\n",
    "\n",
    "\n",
    "\n",
    "clear_param()\n",
    "set_param(0.3, 0.6)\n",
    "show_param()\n",
    "result = apriori(df_pure)\n",
    "result\n",
    "#print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ef624c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#顯示當前參數\n",
    "def show_param(*args):\n",
    "    print('support: ', support)\n",
    "    print('confidence: ', confidence)\n",
    "    print('size: ', size)\n",
    "    print('itemset_dict: ', itemset_dict)\n",
    "    print('frequent_itemset_list: ', frequent_itemset_list)\n",
    "\n",
    "    \n",
    "#清空參數\n",
    "def clear_param(*args):\n",
    "    \n",
    "    #set_param()\n",
    "    \n",
    "    \"\"\"\n",
    "    global support \n",
    "    support = 0.6\n",
    "    global cofidence\n",
    "    cofidence = 0.6\n",
    "    \"\"\"\n",
    "    \n",
    "    global size\n",
    "    size = 2\n",
    "    global itemset_dict\n",
    "    itemset_dict = {}  #用來存放frequent itemset的dict。每個itemset用tuple來存放; 存size = 1 開始\n",
    "    #temp_dict = {}  #用來存放itemset()回傳的list，若為空list，則得到的frequent itemset list 為 itemset_list\n",
    "    global frequent_itemset_list\n",
    "    frequent_itemset_list = []\n",
    "    \n",
    "def set_param(sup = 0.6, con = 0.6):\n",
    "    global support\n",
    "    support = sup\n",
    "    \n",
    "    global confidence\n",
    "    confidence = con\n",
    "    \n",
    "    print('參數設定完成。support = {}, confidence = {}'.format(support, confidence))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e018f7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "support:  0.1\n",
      "confidence:  0.6\n",
      "size:  2\n",
      "itemset_dict:  {}\n",
      "frequent_itemset_list:  []\n"
     ]
    }
   ],
   "source": [
    "#show_param()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "65599e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "參數設定完成。support = 0.2, confidence = 0.6\n"
     ]
    }
   ],
   "source": [
    "#clear_param()\n",
    "#set_param(sup=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3647ea9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "呼叫combine\n",
      "[[1, 2], [1, 3], [1, 4], [1, 5], [2, 3], [2, 4], [2, 5], [3, 4], [3, 5], [4, 5]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "#測試combine\n",
    "my_list = [1,2,3,4,5]\n",
    "n = 2\n",
    "print(combine(my_list, n))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fa1349",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
